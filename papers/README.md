# Downloaded Papers

This directory contains academic papers relevant to the research topic: "Do LLMs behave differently when the prompter is human vs another LLM?"

## Papers List

### 1. How Close is ChatGPT to Human Experts? (HC3 Dataset)
- **File**: `2301.07597_hc3_human_chatgpt_comparison.pdf`
- **Authors**: Guo et al.
- **Year**: 2023
- **arXiv**: [2301.07597](https://arxiv.org/abs/2301.07597)
- **Why relevant**: Foundation paper for human vs ChatGPT text comparison; provides linguistic analysis and detection methods

### 2. HC3 Plus: A Semantic-Invariant Human ChatGPT Comparison Corpus
- **File**: `2309.02731_hc3_plus.pdf`
- **Authors**: Su et al.
- **Year**: 2023
- **arXiv**: [2309.02731](https://arxiv.org/abs/2309.02731)
- **Why relevant**: Extended HC3 dataset with semantic-invariant tasks; improved detection methods

### 3. Towards Understanding Sycophancy in Language Models
- **File**: `2310.13548_sycophancy_understanding.pdf`
- **Authors**: Sharma, Tong, et al. (Anthropic)
- **Year**: 2024 (ICLR)
- **arXiv**: [2310.13548](https://arxiv.org/abs/2310.13548)
- **Why relevant**: Shows LLMs adapt behavior based on perceived user preferences; provides framework for understanding behavioral differences

### 4. When "A Helpful Assistant" Is Not Really Helpful: Personas in System Prompts
- **File**: `2311.10054_personas_not_helpful.pdf`
- **Authors**: Multiple
- **Year**: 2023
- **arXiv**: [2311.10054](https://arxiv.org/abs/2311.10054)
- **Why relevant**: Studies effect of persona prompting on LLM behavior

### 5. Large Language Model based Multi-Agents: A Survey
- **File**: `2402.01680_llm_multi_agents_survey.pdf`
- **Authors**: Multiple
- **Year**: 2024 (IJCAI)
- **arXiv**: [2402.01680](https://arxiv.org/abs/2402.01680)
- **Why relevant**: Comprehensive survey of LLM-to-LLM communication and multi-agent systems

### 6. Quantifying the Persona Effect in LLM Simulations
- **File**: `2402.10811_persona_effect_quantifying.pdf`
- **Authors**: Multiple
- **Year**: 2024
- **arXiv**: [2402.10811](https://arxiv.org/abs/2402.10811)
- **Why relevant**: Methodology for quantifying behavioral differences in LLMs based on persona

### 7. Detecting AI Generated Text Based on NLP and Machine Learning Approaches
- **File**: `2404.10032_ai_text_detection_nlp_ml.pdf`
- **Authors**: Multiple
- **Year**: 2024
- **arXiv**: [2404.10032](https://arxiv.org/abs/2404.10032)
- **Why relevant**: Survey of detection methods and linguistic features for distinguishing human vs AI text

### 8. RAID: A Shared Benchmark for Robust Evaluation of Machine-Generated Text Detectors
- **File**: `2405.07940_raid_benchmark.pdf`
- **Authors**: Dugan et al.
- **Year**: 2024 (ACL)
- **arXiv**: [2405.07940](https://arxiv.org/abs/2405.07940)
- **Why relevant**: Largest benchmark for machine-generated text detection; shows model-specific patterns in generated text

### 9. How Susceptible are LLMs to Influence in Prompts?
- **File**: `2408.11865_llm_susceptible_influence.pdf`
- **Authors**: Anagnostidis & Bulian
- **Year**: 2024 (COLM)
- **arXiv**: [2408.11865](https://arxiv.org/abs/2408.11865)
- **Why relevant**: **CRITICAL** - Directly shows LLMs behave differently based on perceived source authority and characteristics

## Summary Statistics
- **Total papers**: 9
- **Total size**: ~10 MB
- **Date range**: 2023-2024
- **Key venues**: ICLR 2024, ACL 2024, COLM 2024, IJCAI 2024, arXiv
