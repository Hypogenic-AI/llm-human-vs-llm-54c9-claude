@article{guo2023hc3,
  title={How Close is {ChatGPT} to Human Experts? Comparison Corpus, Evaluation, and Detection},
  author={Guo, Biyang and Zhang, Xin and Wang, Ziyuan and Jiang, Minqi and Nie, Jinran and Ding, Yuxuan and Yue, Jianwei and Wu, Yupeng},
  journal={arXiv preprint arXiv:2301.07597},
  year={2023}
}

@inproceedings{sharma2024sycophancy,
  title={Towards Understanding Sycophancy in Language Models},
  author={Sharma, Mrinank and Tong, Meg and Korbak, Tomasz and Duvenaud, David and Askell, Amanda and Bowman, Samuel R and Cheng, Newton and Durmus, Esin and Hatfield-Dodds, Zac and Johnston, Scott R and others},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2024}
}

@inproceedings{anagnostidis2024susceptible,
  title={How Susceptible are {LLMs} to Influence in Prompts?},
  author={Anagnostidis, Sotiris and Bulian, Jannis},
  booktitle={Conference on Language Modeling (COLM)},
  year={2024}
}

@inproceedings{dugan2024raid,
  title={{RAID}: A Shared Benchmark for Robust Evaluation of Machine-Generated Text Detectors},
  author={Dugan, Liam and Hwang, Alyssa and Trhl{\'\i}k, Filip and Zhu, Andrew and Luber, Josh and Ippolito, Daphne and Callison-Burch, Chris},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (ACL)},
  year={2024}
}

@article{su2023hc3plus,
  title={{HC3} Plus: A Semantic-Invariant Human {ChatGPT} Comparison Corpus},
  author={Su, Yicheng and Wang, Zhenmei and Chen, Zhaoqiang},
  journal={arXiv preprint arXiv:2309.02731},
  year={2023}
}

@inproceedings{guo2024multiagent,
  title={Large Language Model based Multi-Agents: A Survey of Progress and Challenges},
  author={Guo, Taicheng and Chen, Xiuying and Wang, Yaqi and Chang, Ruyi and Pei, Shichao and Chawla, Nitesh V and Wiest, Olaf and Zhang, Xiangliang},
  booktitle={International Joint Conference on Artificial Intelligence (IJCAI)},
  year={2024}
}

@article{zheng2023personas,
  title={When ``A Helpful Assistant'' Is Not Really Helpful: Personas in System Prompts Do Not Improve Performances of Large Language Models},
  author={Zheng, Mingqian and Pei, Jiaxin and Jurgens, David},
  journal={arXiv preprint arXiv:2311.10054},
  year={2023}
}

@article{wang2024persona,
  title={Quantifying the Persona Effect in {LLM} Simulations},
  author={Wang, Tiancheng and Lyu, Yuanshun and Wei, Jerry and others},
  journal={arXiv preprint arXiv:2402.10811},
  year={2024}
}

@article{ahmed2024detection,
  title={Detecting {AI} Generated Text Based on {NLP} and Machine Learning Approaches},
  author={Ahmed, Mohammed and others},
  journal={arXiv preprint arXiv:2404.10032},
  year={2024}
}

@article{brown2020gpt3,
  title={Language Models are Few-Shot Learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{openai2023gpt4,
  title={{GPT-4} Technical Report},
  author={OpenAI},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{anthropic2024claude,
  title={The Claude 3 Model Family: A New Standard for Intelligence},
  author={Anthropic},
  year={2024}
}

@article{cohen1988statistical,
  title={Statistical Power Analysis for the Behavioral Sciences},
  author={Cohen, Jacob},
  journal={Lawrence Erlbaum Associates},
  edition={2nd},
  year={1988}
}

@article{flesch1948readability,
  title={A New Readability Yardstick},
  author={Flesch, Rudolph},
  journal={Journal of Applied Psychology},
  volume={32},
  number={3},
  pages={221--233},
  year={1948}
}

@article{kincaid1975derivation,
  title={Derivation of New Readability Formulas for Navy Enlisted Personnel},
  author={Kincaid, J Peter and Fishburne Jr, Robert P and Rogers, Richard L and Chissom, Brad S},
  journal={Research Branch Report 8-75, Naval Technical Training Command},
  year={1975}
}

@inproceedings{perez2022red,
  title={Red Teaming Language Models with Language Models},
  author={Perez, Ethan and Ringer, Sam and Lukosiute, Kamile and Nguyen, Karina and Chen, Edwin and Heiner, Scott and Pettit, Craig and Olsson, Catherine and Kundu, Sandipan and Kadavath, Saurav and others},
  booktitle={Empirical Methods in Natural Language Processing (EMNLP)},
  year={2022}
}

@article{giles1991accommodation,
  title={Accommodation Theory: Communication, Context, and Consequence},
  author={Giles, Howard and Coupland, Nikolas and Coupland, Justine},
  journal={Contexts of Accommodation: Developments in Applied Sociolinguistics},
  pages={1--68},
  year={1991},
  publisher={Cambridge University Press}
}

@article{ouyang2022instructgpt,
  title={Training Language Models to Follow Instructions with Human Feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@inproceedings{wei2024jailbroken,
  title={Jailbroken: How Does {LLM} Safety Training Fail?},
  author={Wei, Alexander and Haghtalab, Nika and Steinhardt, Jacob},
  booktitle={Advances in Neural Information Processing Systems},
  year={2024}
}
